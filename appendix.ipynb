{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72a4f722",
   "metadata": {},
   "source": [
    "## Train test split for future model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f437ac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=17)\n",
    "\n",
    "print(f\"X_train is a DataFrame with {X_train.shape[0]} rows and {X_train.shape[1]} columns\")\n",
    "print(f\"y_train is a Series with {y_train.shape[0]} values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d460dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "condition = X_train[[\"condition\"]]\n",
    "\n",
    "# (2) Instantiate a OneHotEncoder with categories=\"auto\",\n",
    "# sparse=False, and handle_unknown=\"ignore\"\n",
    "ohe = OneHotEncoder(categories=\"auto\", sparse=False, handle_unknown=\"ignore\")\n",
    "\n",
    "# (3) Fit the encoder on fireplace_qu_train\n",
    "ohe.fit(condition)\n",
    "\n",
    "# Inspect the categories of the fitted encoder\n",
    "ohe.categories_\n",
    "\n",
    "condition_encoded = ohe.transform(condition)\n",
    "\n",
    "# (5a) Make the transformed data into a dataframe\n",
    "condition_encoded = pd.DataFrame(\n",
    "    # Pass in NumPy array\n",
    "    condition_encoded,\n",
    "    # Set the column names to the categories found by OHE\n",
    "    columns=ohe.categories_[0],\n",
    "    # Set the index to match X_train's index\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "X_train.drop(\"condition\", axis=1, inplace=True)\n",
    "\n",
    "X_train = pd.concat([X_train, condition_encoded], axis=1)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73f7dba",
   "metadata": {},
   "source": [
    "### Transforming Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11ba1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep relevant columns\n",
    "X_test = X_test.loc[:, relevant_columns]\n",
    "\n",
    "#continuous = ['sqft_living', 'sqft_lot']\n",
    "#categoricals = ['grade', 'condition', 'bedrooms', 'bathrooms', 'floors', \n",
    "#                'waterfront', 'mth_sold', 'view', 'zipcode']\n",
    "#dummy_cat = ['condition', 'waterfront', 'view']\n",
    "\n",
    "df_cont = X_test[continuous]\n",
    "\n",
    "# take the log of continuous variables\n",
    "log_names = [f'{column}_log' for column in df_cont.columns]\n",
    "\n",
    "df_log = np.log(df_cont)\n",
    "df_log.columns = log_names\n",
    "\n",
    "# normalize (subract mean and divide by std)\n",
    "def normalize(feature):\n",
    "    return (feature - feature.mean()) / feature.std()\n",
    "\n",
    "df_log_norm = df_log.apply(normalize)\n",
    "\n",
    "# take log and normalize y\n",
    "y_log_test = pd.DataFrame(np.log(y_test))\n",
    "y_norm_test = y_log_test.apply(normalize)\n",
    "\n",
    "\n",
    "# categoricals\n",
    "df_ohe = pd.get_dummies(X_test[dummy_cat], prefix=dummy_cat, drop_first=True)\n",
    "\n",
    "floors_dummies = pd.get_dummies(X_test['floors'], prefix='floors', drop_first=True)\n",
    "bedrooms_dummies = pd.get_dummies(X_test['bedrooms'], prefix='beds', drop_first=True)\n",
    "zipcode_dummies = pd.get_dummies(X_test['zipcode'], prefix='zip', drop_first=True)\n",
    "\n",
    "# join categorical and continuous dataframes together, drop original columns\n",
    "X_test_preprocessed = pd.concat([df_log_norm, df_ohe, floors_dummies, \n",
    "                                 bedrooms_dummies, zipcode_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ad75e8",
   "metadata": {},
   "source": [
    "These are the R^2 values of the train and test models using a linear regression with square footage of the living room as the independent variable and listing price as the dependent variable. We get similar R^2s for each, around 0.5, which  is a good sign that the model is predicting the test data correctly, but is a fairly low R^2 for an inferential model as currently it only explains around 50% of the variation in house price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1318c738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores using cross validation with 10 splits\n",
    "\n",
    "X_base = X_train[[most_correlated_feature]]\n",
    "\n",
    "base_model = LinearRegression()\n",
    "base_model.fit(X_base, y_train)\n",
    "\n",
    "splitter = ShuffleSplit(n_splits=10, test_size=0.25, random_state=0)\n",
    "\n",
    "baseline_scores = cross_validate(\n",
    "    estimator=base_model,\n",
    "    X=X_base,\n",
    "    y=y_train,\n",
    "    return_train_score=True,\n",
    "    cv=splitter\n",
    ")\n",
    "\n",
    "print(\"Train score:     \", baseline_scores[\"train_score\"].mean())\n",
    "print(\"Validation score:\", baseline_scores[\"test_score\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5b1876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores using single test/train split\n",
    "\n",
    "base_model.fit(X_base, y_train)\n",
    "\n",
    "print(\"Train R^2: \", str(base_model.score(X_base, y_train)))\n",
    "print(\"Test R^2: \", base_model.score(X_test[[most_correlated_feature]], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd82f2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_base = X[[most_correlated_feature]]\n",
    "base_model = LinearRegression()\n",
    "base_model.fit(X_base, y)\n",
    "print(\"BASE R^2: \", str(base_model.score(X_base, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c792e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(X[continuous], figsize=(20,20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7fe800",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'price~sqft_living'\n",
    "#f2 = 'sales~radio'\n",
    "model = smf.ols(formula=f, data=data_ols).fit()\n",
    "#model2 = smf.ols(formula=f2, data=data).fit()\n",
    "\n",
    "resid1 = model.resid\n",
    "#resid2 = model2.resid\n",
    "fig = sm.graphics.qqplot(resid1, dist=stats.norm, line='45', fit=True)\n",
    "#fig = sm.graphics.qqplot(resid2, dist=stats.norm, line='45', fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737d97f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linearity\n",
    "\n",
    "X_final = X_preprocessed # add when finished\n",
    "y_final = y\n",
    "\n",
    "preds = second_model.predict(X_final)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "perfect_line = np.arange(y_final.min(), y_final.max())\n",
    "ax.plot(perfect_line, linestyle=\"--\", color=\"orange\", label=\"Perfect Fit\")\n",
    "ax.scatter(y_final, preds, alpha=0.5)\n",
    "ax.set_xlabel(\"Actual Price\")\n",
    "ax.set_ylabel(\"Predicted Price\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa100217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log transform continuous variables where it makes sense\n",
    "\n",
    "# log cols\n",
    "cols_log = ['sqft_living', 'sqft_lot', 'sqft_above', 'sqft_living15', 'sqft_lot15']\n",
    "\n",
    "df_transf = pd.DataFrame([])\n",
    "\n",
    "for feat in cols_log:\n",
    "    df_transf[feat] = X[feat].map(lambda x: np.log(x))\n",
    "    \n",
    "def normalize(feature):\n",
    "    return (feature - feature.mean()) / feature.std()\n",
    "\n",
    "features_final = df_transf.apply(normalize)\n",
    "\n",
    "features_final.hist(figsize  = [20, 20], bins='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055bd693",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Normalize log\n",
    "\n",
    "# normalize (subract mean and divide by std)\n",
    "def normalize(feature):\n",
    "    return (feature - feature.mean()) / feature.std()\n",
    "\n",
    "# apply normalization function\n",
    "df_log_norm = df_log.apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61df67cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def calculate_residuals(model, features, label):\n",
    "#    \"\"\"\n",
    "#    Creates predictions on the features with the model and calculates residuals\n",
    "#    \"\"\"\n",
    "#    predictions = model.predict(features)\n",
    "#    df_results = pd.DataFrame({'Actual': label, 'Predicted': predictions})\n",
    "#    df_results['Residuals'] = abs(df_results['Actual']) - abs(df_results['Predicted'])\n",
    "    \n",
    "#    return df_results\n",
    "\n",
    "preds = model.predict(X_model)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "perfect_line = np.arange(y_model.min(), y_model.max())\n",
    "#ax.plot(perfect_line, linestyle=\"--\", color=\"orange\", label=\"Perfect Fit\")\n",
    "ax.scatter(y_model, preds, alpha=0.5)\n",
    "ax.set_xlabel(\"Actual Price\")\n",
    "ax.set_ylabel(\"Predicted Price\")\n",
    "ax.legend();\n",
    "\n",
    "plt.plot(perfect_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f2b191",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### EXTRA ######\n",
    "\n",
    "#join categorical and continuous dataframes together, drop original columns\n",
    "X_preprocessed = X.drop(categoricals, axis=1)\n",
    "X_preprocessed = pd.concat([X_preprocessed, df_ohe, zipcode_dummies], axis=1) #df_cont?\n",
    "\n",
    "X_preprocessed\n",
    "\n",
    "#X_preprocessed = pd.concat([df_log_norm, df_ohe, condition_dummies, #floors_dummies, bedrooms_dummies, \n",
    "#                                  zipcode_dummies, X[other_continuous]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db9deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_model = LinearRegression()\n",
    "second_model.fit(X_preprocessed, y_norm)\n",
    "\n",
    "print(\"Second Model R^2: \", second_model.score(X_preprocessed, y_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7949c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize (subract mean and divide by std)\n",
    "\n",
    "def normalize(feature):\n",
    "    return (feature - feature.mean()) / feature.std()\n",
    "\n",
    "df_log_norm = df_log.apply(normalize)\n",
    "\n",
    "y_log = pd.DataFrame(np.log(y))\n",
    "y_norm = y_log.apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4ef42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_cols = ['sqft_living', 'sqft_lot']\n",
    "other_continuous = ['floors', 'bedrooms']\n",
    "categoricals = ['grade', 'condition', 'bedrooms', 'bathrooms', 'floors', \n",
    "                'waterfront', 'mth_sold', 'view', 'zipcode']\n",
    "dummy_cat = ['condition', 'waterfront', 'view']\n",
    "\n",
    "# log transform\n",
    "df_cont = X[log_cols]\n",
    "log_names = [f'{column}_log' for column in df_cont.columns]\n",
    "\n",
    "df_log = np.log(df_cont)\n",
    "df_log.columns = log_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77f3914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independence (would be train)\n",
    "\n",
    "X_final = X_train_preprocessed\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "vif = [variance_inflation_factor(X_final.values, i) for i in range(X_final.shape[1])]\n",
    "pd.Series(vif, index=X_final.columns, name=\"Variance Inflation Factor\") # looking for below 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
